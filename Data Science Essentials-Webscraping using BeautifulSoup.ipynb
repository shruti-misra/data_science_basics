{"cells":[{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":181,"status":"ok","timestamp":1691619962658,"user":{"displayName":"Shruti Misra","userId":"11216241389951476389"},"user_tz":420},"id":"UX-k6OPHnsuM"},"outputs":[],"source":["#Import relevant libraries\n","import matplotlib.pyplot as plt\n","import numpy as np, pandas as pd\n","import seaborn as sns\n","import requests\n","from bs4 import BeautifulSoup\n","import sqlalchemy\n","import re\n","import urllib.request"]},{"cell_type":"markdown","source":["## Importing ARPA-E project information\n","\n","For my research, I wanted to look at all the projects funded by ARPA-E. To do this, I scraped their website to get a dataframe of all the projects along with project information. I also noted from reading ARPA-E's funding reports that the \"Year\" noted in the project information was different than the year that the project was actually funded, I called this sponsoring year. I assumed that the \"sponsoring year\" was the year that the specific project showed up on the ARPA-E website."],"metadata":{"id":"JCK8QfqTeuaC"}},{"cell_type":"code","source":["def scrape(save):\n","  url='https://arpa-e.energy.gov/technologies/projects'\n","  page = 1\n","  projects = []\n","  while url:\n","\n","    #Print Page number\n","    print(\"Page: \", page)\n","\n","    #Ping URL\n","    response = requests.get(url)\n","\n","    #Create BeautifulSoup object\n","    soup = BeautifulSoup(response.text, 'html.parser')\n","\n","    #Get all of the projects on a given page\n","    blog_titles = soup.findAll('span', attrs={\"class\":\"bold-link\"})\n","    for link in blog_titles:\n","\n","      #For each project, find and go to the link of it's respective project page\n","      url1 = \"https://arpa-e.energy.gov\" + link.find('a')['href']\n","      response1 = requests.get(url1)\n","\n","      #Create BeautifulSoup object for the project\n","      soup1 = BeautifulSoup(response1.text, 'html.parser')\n","\n","      #Get company name for the project\n","      company = soup1.find('h1', attrs={\"class\":\"inner-page-title\"}).text.strip()\n","      print(company)\n","      tags = soup1.find('div', attrs = {\"class\": \"tag\"}).text.strip().split('\\n')\n","\n","      #Get critical need that the project addresses\n","      need = soup1.find(\"h3\", text=\"Critical Need:\").parent.find('div').text if soup1.find(\"h3\", text=\"Critical Need:\") else []\n","\n","      #Get the advantage that the project promises\n","      advantage = soup1.find(\"h3\", text=\"Project Innovation + Advantages: \").parent.find('div').text.strip()\n","\n","      #If the award amount is given then get that as well\n","      if '$'in soup1.find(\"span\", text=\"Award:\").parent.text:\n","        award = soup1.find(\"span\", text=\"Award:\").parent.text.strip().split('$')[1].strip()\n","      else:\n","        continue\n","\n","      #Find the location (city, state) along with the project year, funding year and status for the project and the partner organizations\n","      location_state = soup1.find(\"span\", text=\"Location:\").parent.text.strip().split(':')[1].split(',')[1].strip() if ',' in soup1.find(\"span\", text=\"Location:\").parent.text.strip().split(':')[1] else []\n","      location_city = soup1.find(\"span\", text=\"Location:\").parent.text.strip().split(':')[1].split(',')[0].strip() if ',' in soup1.find(\"span\", text=\"Location:\").parent.text.strip().split(':')[1] else []\n","      project_year = soup1.find(\"span\", text=\"Project Term:\").parent.text.strip().split(':')[1].split('-')[0].strip()[-4:]\n","      funding_year = soup1.find('div', attrs = {\"class\": \"project-bottom\"}).text.strip()[-4:] if 'Release Date' in soup1.find('div', attrs = {\"class\": \"project-bottom\"}).text.strip() else []\n","      status = soup1.find(\"span\", text=\"Status:\").parent.text.strip().split(':')[1].strip()\n","      partners = soup1.find('div', attrs = {\"class\": \"project-bottom\"}).find('div', attrs={\"class\":\"col\"}).text.strip().split('\\n') if soup1.find('div', attrs = {\"class\": \"project-bottom\"}).find('div', attrs={\"class\":\"col\"}) else []\n","      m = [company, project_year, funding_year, float(award.replace(',', '')), status, location_city, location_state, tags, need, advantage, partners]\n","      #Append it to the list of all projects\n","      projects.append(m)\n","    #Update URL to point to next page\n","    url = \"https://arpa-e.energy.gov/technologies/projects\"+ soup.find('li', attrs={\"class\": \"pager__item pager__item--next\"}).find('a')['href'] if soup.find('li', attrs={\"class\": \"pager__item pager__item--next\"}) else None\n","    page += 1\n","  #Create dataframe with all projects and it's information\n","  data = pd.DataFrame(projects, columns=['Company', 'ProjectYear', 'FundingYear', 'Award', 'Status', 'City', 'State', 'Tags', 'Need', 'Advantage', 'Partners'])\n","\n","  #If save is True then save the CSV to the location\n","  if save:\n","    from google.colab import drive\n","    drive.mount('/content/drive')\n","    data.to_csv('/content/drive/MyDrive/Grad School-Files/U-I partnerships: Energy/Data/arpa_new.csv')\n","  return data\n","data = scrape(True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qup0LBfyaK3c","executionInfo":{"status":"ok","timestamp":1691620843821,"user_tz":420,"elapsed":7,"user":{"displayName":"Shruti Misra","userId":"11216241389951476389"}},"outputId":"c25a9b96-8d4f-49ed-9dae-52da57143969"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["<a href=\"https://open.gsa.gov/api/dap/\" rel=\"noopener\" target=\"_blank\">API</a>\n","<a href=\"https://analytics.usa.gov/data/live/all-pages-realtime.csv\">Download the full dataset.</a>\n","<a href=\"https://analytics.usa.gov/data/live/all-domains-30-days.csv\">Download the full dataset.</a>\n","<a class=\"external-link\" href=\"https://digital.gov/services/dap/\">Digital Analytics Program</a>\n","<a class=\"external-link\" href=\"https://digital.gov/services/dap/common-questions-about-dap-faq/#part-4\">does not track individuals</a>\n","<a class=\"external-link\" href=\"https://support.google.com/analytics/answer/2763052?hl=en\">anonymizes the IP addresses</a>\n","<a class=\"external-link\" href=\"https://analytics.usa.gov/data/live/second-level-domains.csv\">400 executive branch government domains</a>\n","<a class=\"external-link\" href=\"https://analytics.usa.gov/data/live/sites.csv\">about 5,700 total websites</a>\n","<a href=\"https://open.gsa.gov/api/dap/\" rel=\"noopener\" target=\"_blank\">API</a>\n","<a class=\"usa-button usa-button-secondary-inverse\" href=\"https://github.com/18F/analytics.usa.gov/issues\">\n","<img alt=\"Github Icon\" class=\"github-icon\" src=\"/images/github-logo-white.svg\"/>\n","                  Suggest a feature or report an issue\n","            </a>\n","<a href=\"https://github.com/18F/analytics.usa.gov\">\n","<img alt=\"Github Icon\" class=\"github-icon\" src=\"/images/github-logo.svg\"/>\n","              View application code on GitHub</a>\n","<a href=\"https://github.com/18F/analytics-reporter\">\n","<img alt=\"Github Icon\" class=\"github-icon\" src=\"/images/github-logo.svg\"/>\n","              View code for the data on GitHub</a>\n","<a href=\"https://www.gsa.gov/\">\n","<img alt=\"GSA\" src=\"/images/gsa-logo.svg\"/>\n","</a>\n","<a href=\"https://digital.gov/guides/dap/\">Digital Analytics Program</a>\n","<a href=\"https://cloud.gov/\">cloud.gov</a>\n"]}]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM0HNVM1uZl5AMpd1DBMPQk"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}